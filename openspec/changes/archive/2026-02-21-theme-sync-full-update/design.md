## Context

当前题材同步采用基于哈希的增量同步策略，通过比较远程和本地数据的哈希值来确定变更。这种实现方式在 `SyncConceptsHandler` 中逐个处理题材，对于新增、修改和删除的题材分别采用不同的处理逻辑。

当前实现的问题：
1. 增量同步逻辑复杂，需要处理三种状态（新增、修改、删除）
2. 每个题材都需要单独提交事务，导致性能开销
3. 删除操作可能导致外键约束问题
4. 状态管理复杂，容易出现数据不一致

用户需求是改为全量同步，但不采用删除再插入的方式，以保持数据完整性和性能。

## Goals / Non-Goals

**Goals:**
- 简化同步逻辑，从增量同步改为全量同步
- 减少事务提交次数，提高性能
- 保持数据完整性，避免删除再重建
- 保持现有 API 接口不变
- 维持现有的错误处理和日志记录机制

**Non-Goals:**
- 不修改数据库表结构
- 不改变 API 接口签名
- 不修改概念和股票的基本数据模型
- 不影响其他模块的同步逻辑

## Decisions

### 决策1：采用批量全量同步策略
**选择**: 一次性获取所有远程数据，与本地数据进行批量比较和更新
**理由**: 
- 简化逻辑，避免逐个处理题材的复杂性
- 减少数据库事务次数，提高性能
- 保证数据最终一致性

**替代方案考虑**:
- 保留增量同步：但逻辑复杂，容易出错
- 删除再插入：性能开销大，可能破坏外键关系

### 决策2：保持单题材事务模式
**选择**: 每个题材的处理仍然使用独立事务，但采用批量操作
**理由**:
- 保持现有的事务边界和错误隔离
- 避免长时间锁定数据库资源
- 便于定位和修复单个题材的问题
- 与现有监控和日志系统兼容

### 决策3：使用 UPSERT 模式
**选择**: 对于概念和股票关系都采用 UPSERT（插入或更新）模式
**理由**:
- 避免复杂的删除逻辑
- 保持数据完整性
- 利用数据库的 ON CONFLICT 机制

### 决策4：题材级别的延迟删除策略
**选择**: 在每个题材的 UPSERT 操作完成后，删除该题材中不再存在的股票关系
**理由**:
- 保持事务边界的清晰性
- 确保每个题材的数据一致性
- 避免跨题材的删除操作
- 便于错误追踪和恢复

## Risks / Trade-offs

**风险**: 内存使用增加
- **原因**: 需要在内存中保存所有远程数据和本地数据的映射
- **缓解**: 使用生成器和分批处理，避免一次性加载所有数据

**风险**: 数据库连接时间增长
- **原因**: 全量同步可能需要更长的数据库连接时间
- **缓解**: 优化批量操作，使用连接池，设置合理的超时

**权衡**: 性能 vs 简单性
- **选择**: 牺牲部分性能换取逻辑简单性和可维护性
- **理由**: 题材同步频率不高，简单性更重要

## Migration Plan

1. **准备阶段**
   - 备份当前同步逻辑代码
   - 准备测试数据和验证脚本

2. **实现阶段**
   - 修改 `SyncConceptsHandler` 的主逻辑
   - 实现批量 UPSERT 方法
   - 添加详细的日志记录

3. **测试阶段**
   - 单元测试验证批量操作
   - 集成测试验证完整同步流程
   - 性能测试验证改进效果

4. **部署阶段**
   - 灰度发布，先在测试环境验证
   - 监控同步性能和错误率
   - 准备回滚方案

## Open Questions

1. 批量操作的最佳批次大小是多少？
2. 如何处理同步过程中的部分失败情况？
3. 是否需要添加同步进度跟踪机制？
4. 如何优化大量数据的内存使用？
